{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split .pdfs to fit Google cloud limit of max 10 pages\n",
    "\n",
    "def split_max_page_10(directory,output_directory):\n",
    "    import os\n",
    "    from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "    import shutil\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.mkdir(output_directory)\n",
    "\n",
    " #   if not os.path.exists(os.path.join(output_directory,'untouched')):\n",
    " #       os.mkdir(os.path.join(output_directory,'untouched'))\n",
    "\n",
    "    for document in os.listdir(directory):\n",
    "        \n",
    "        if not os.path.isdir(f\"{directory}/{document}\"):\n",
    "            inputpdf = PdfFileReader(open(f\"{directory}/{document}\", \"rb\"))\n",
    "            x=int(0)\n",
    "            i=int(0)\n",
    "\n",
    "            if inputpdf.numPages>10:\n",
    "                while i<inputpdf.numPages:\n",
    "                    output = PdfFileWriter()\n",
    "\n",
    "                    for i in range((10*x),(10*(x+1))):\n",
    "                        try: \n",
    "                            output.addPage(inputpdf.getPage(i))\n",
    "                        except:\n",
    "                            break\n",
    "                    with open(f\"{output_directory}/{document}__{x}.pdf\", \"wb\") as outputStream:\n",
    "                        output.write(outputStream)\n",
    "                    print(f\"{output_directory}/{document}__{x}.pdf ... DONE\", end='\\r')\n",
    "                    x+=1\n",
    " #           else:\n",
    " #               src_file = os.path.join(directory,document)\n",
    " #               dst_path = os.path.join(f'{output_directory}/untouched')\n",
    " #               dst_file = os.path.join(dst_path,document)\n",
    " #\n",
    " #               shutil.copy(src_file, dst_file)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the function\n",
    "# NOTICE::\n",
    "# DELETE all THE fixed FILES WITH 1kB filesize afterwards!\n",
    "\n",
    "directory='../unprocessed_data'\n",
    "output_directory='../unprocessed_data/fixed'\n",
    "\n",
    "directory='../Nederlands'\n",
    "output_directory='../Nederlands/fixed'\n",
    "\n",
    "directory='../Francais'\n",
    "output_directory='../Francais/fixed'\n",
    "\n",
    "directory='../processed_data/too_large'\n",
    "output_directory='../processed_data/too_large/fixed'\n",
    "\n",
    "#split_max_page_10(directory,output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine the split .txt files into one file\n",
    "# Scans fils in input folder for .txt in parts\n",
    "# Moves the joined .txt file to output folder\n",
    "# Then you can delete the parted .txt files in input folder safely\n",
    "\n",
    "def combine_txt_files():\n",
    "    import os\n",
    "    import re\n",
    "    from os import listdir\n",
    "\n",
    "    path=\"../processed_data\"\n",
    "    output_path='../processed_data_combined'\n",
    "    entries = listdir(path)\n",
    "    directories=[]\n",
    "\n",
    "    if not os.path.exists(os.path.join(output_path)):\n",
    "        os.mkdir(f'{output_path}')\n",
    "        \n",
    "    for entry in entries:\n",
    "        if os.path.isdir(os.path.join(path,entry)):\n",
    "            directories.append(entry)\n",
    "    \n",
    "    for directory in directories:\n",
    "        files_in_path=listdir(os.path.join(path,directory))\n",
    "            \n",
    "        if not os.path.exists(os.path.join(output_path,directory)):\n",
    "            os.mkdir(f'{output_path}/{directory}')\n",
    "\n",
    "        for file in files_in_path:\n",
    "            \n",
    "            if file.find('__') != -1: \n",
    "\n",
    "                page=re.findall(r'__(.*)',file) \n",
    "                page=page[0][:-4]\n",
    "\n",
    "                document_id=re.sub(page[0],'',file)\n",
    "                document_id=re.sub(f'__{page}','',file)\n",
    "\n",
    "                dir=os.path.join(path,directory)\n",
    "                file=os.path.join(dir,file)\n",
    "\n",
    "                x=int(0)\n",
    "                data=str()\n",
    "\n",
    "                with open(file,encoding=\"utf-8\") as fp:\n",
    "                \n",
    "                    data += fp.read()\n",
    "\n",
    "                # now we have the output file ready\n",
    "                output=os.path.join(output_path,directory)\n",
    "                output=os.path.join(output,document_id)\n",
    "\n",
    "                with open (output, 'a',encoding=\"utf-8\") as fp:\n",
    "                    fp.write(data)\n",
    "\n",
    "                    \n",
    "    #print(files_in_path)\n",
    "    print(directories)\n",
    "\n",
    "# You can now safely delete the .txt part files in /processed_data/NL and FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excecute the combine_txt function\n",
    "\n",
    "#combine_txt_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "googenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a7e325ecc84fa625d8a3ed09038798785ca9ae88cae94e662f38988cc00c57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
