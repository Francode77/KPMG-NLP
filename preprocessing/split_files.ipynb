{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from statistics import mean,median\n",
    "from alive_progress import alive_bar\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfrw import PdfReader, PdfWriter, PageMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split .pdf files based on character per line  \n",
    "# Splits on mean and average of character count\n",
    "# Run this for the .pdf files in /data\n",
    "\n",
    "def split_files_vertically():\n",
    "    directory = \"../data\"\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"../split\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    def splitpage(src):\n",
    "        \"\"\"Split a page into two (left and right)\"\"\"\n",
    "        # Yield a result for each half of the page\n",
    "        for x_pos in (0, 0.5):\n",
    "            yield PageMerge().add(src, viewrect=(x_pos, 0, 0.5, 1)).render()\n",
    "\n",
    "    split = 0\n",
    "    y=0\n",
    "    already_done=os.listdir('split')\n",
    "    print (len(already_done))\n",
    "    dirs=os.listdir(directory)\n",
    "    for dir in dirs:\n",
    "        paths=os.listdir(f\"{directory}/{dir}\")\n",
    "        for document in paths :\n",
    "            y+=1\n",
    "            print (y,end='\\r')\n",
    "            if document[-4:]=='.pdf' and document not in already_done:\n",
    "                text = extract_text(f\"{directory}/{dir}/{document}\")\n",
    "                x=[]\n",
    "                #print (text)\n",
    "                for i in text.splitlines():\n",
    "\n",
    "                    # Filter out table data\n",
    "                    if (len(i)>40):\n",
    "\n",
    "                        x.append(len(i))\n",
    "                # Calculate the average length of sentences outside tables\n",
    "                try: \n",
    "                    res_mean=mean(x)\n",
    "                except:\n",
    "                    res_mean=100\n",
    "                try:\n",
    "                    res_median=median(x)\n",
    "                except:\n",
    "                    res_median=100\n",
    "                    print ('Error on file:',document,'\\n')\n",
    "                text = text.splitlines()\n",
    "\n",
    "                if len(max(text, key=len)) <=67 or len(max(text, key=len)) >67 and res_mean <55 and res_median<55:\n",
    "                    #print ('Splitting ',document,end='\\r')\n",
    "                    \n",
    "                    writer = PdfWriter()\n",
    "                    page_number = 0\n",
    "                    for page in PdfReader(f\"{directory}/{dir}/{document}\").pages:\n",
    "                        writer.addpages(splitpage(page))\n",
    "                    writer.write(f\"split/{document}\")\n",
    "                    split += 1\n",
    "  \n",
    "    print(f\"Split pdfs: {split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to join .pdf files after vertical split\n",
    "#\n",
    "# Output files from the split_vertical function splits files in pages sequentially\n",
    "# so they have alternating language per page\n",
    "#\n",
    "# This function makes 2 .pdfs from this file in the corresponding language\n",
    "\n",
    "def join_files_vertically():\n",
    "    path = \"../split\"\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"../Nederlands\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        os.mkdir(\"../Francais\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for document in os.listdir(path):\n",
    "        writer_NL = PdfWriter()\n",
    "        writer_FR = PdfWriter()\n",
    "        page_number = 0\n",
    "        for page in PdfReader(f\"{path}/{document}\").pages: \n",
    "            page_number += 1\n",
    "            if page_number%2 == 1:\n",
    "                writer_NL.addpage(page)\n",
    "            else:\n",
    "                writer_FR.addpage(page)\n",
    "        writer_NL.write(f\"Nederlands/NL_{document}\")\n",
    "        writer_FR.write(f\"Francais/FR_{document}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the above functions once\n",
    "\n",
    "#split_files_vertically()\n",
    "#join_files_vertically()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FASTTEXT LANGUAGE detection \n",
    "import fasttext as ft \n",
    "ft_model = ft.load_model(\"lid.176.ftz\") \n",
    "def fasttext_language_predict(text, model = ft_model): \n",
    "  text = text.replace('\\n', \" \")\n",
    "  prediction = model.predict([text]) \n",
    "  return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_text_horizontally():\n",
    "    \n",
    "    # Function to split the processed .txt files that are NOT vertically split\n",
    "    # based on paragraphs language detection \n",
    "    # in the dataframe obtained after google DocumentAI processing\n",
    "\n",
    "    import numpy as np\n",
    "    import re\n",
    "    df=pd.DataFrame()\n",
    "\n",
    "    input_csv='../new_processed_data.csv'\n",
    "    df=pd.read_csv(input_csv)\n",
    "\n",
    "    # Set the paths\n",
    "    input_path=os.path.join('..','new_processed_data')\n",
    "    output_path=os.path.join('..','new_processed_data')\n",
    "    output_path_NL=os.path.join(output_path,'NL')\n",
    "    output_path_FR=os.path.join(output_path,'FR')\n",
    "\n",
    "    try:\n",
    "        os.mkdir(output_path_NL)\n",
    "        os.mkdir(output_path_FR)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for file in listdir(input_path):\n",
    "\n",
    "        if '.txt' in file:\n",
    "            \n",
    "            document_id=file[:-4]\n",
    "            document_pdf=f'{document_id}.pdf'\n",
    "\n",
    "            x=int (1)\n",
    "            t_nl=int (1)\n",
    "            t_fr=int (1)\n",
    "            \n",
    "            # This keeps a list to remember in what language we are right now\n",
    "            p_language_list=[]\n",
    "\n",
    "            # output paragraphs to text\n",
    "            nl_text=str()\n",
    "            fr_text=str()\n",
    "\n",
    "            while df[df['document_id']==document_pdf][f'p{x}'].values.astype(str)[0]!='nan':\n",
    "                #print (df[df['document_id']==document_pdf]['p5'].values.astype(str))\n",
    "                paragraph=df[df['document_id']==document_pdf][f'p{x}'].values.astype(str)[0]\n",
    "                paragraph=re.sub('\\\\n',' ',paragraph)\n",
    "                \n",
    "                if len(paragraph)>44:\n",
    "                    p_language=fasttext_language_predict(paragraph)[0][0][0][-2:] \n",
    "                    #print (f'{x} : {p_language} {paragraph[:63]}')    \n",
    "\n",
    "                x+=1  \n",
    "\n",
    "                if p_language!='nl' and p_language!='fr':\n",
    "                    try:\n",
    "                        last_language=p_language_list[x-1]\n",
    "                        p_language=last_language\n",
    "                    except:\n",
    "                        last_language=''\n",
    "                else: \n",
    "                    p_language_list.append(p_language)\n",
    "                        \n",
    "                if 'Neerlegging-Dépôt' in paragraph:\n",
    "                    fr_text+=paragraph \n",
    "                    fr_text+='\\n'\n",
    "                    nl_text+=paragraph \n",
    "                    nl_text+='\\n'\n",
    "                    continue\n",
    "                        \n",
    "                if p_language=='nl':\n",
    "                    nl_text+=paragraph\n",
    "                    nl_text+='\\n'\n",
    "                    t_nl+=1\n",
    "                    #nl_text.append('\\n')\n",
    "\n",
    "                if p_language=='fr':\n",
    "                    fr_text+=paragraph\n",
    "                    fr_text+='\\n'\n",
    "                    t_fr+=1\n",
    "                    #fr_text.append('\\n')\n",
    "\n",
    "                # Break if we are at max paragraph column\n",
    "                if x>(len(df.columns)-4): \n",
    "                    break\n",
    "\n",
    "            fr_txt=f'FR_{document_id}.txt'\n",
    "            nl_txt=f'NL_{document_id}.txt'\n",
    "\n",
    "            output_file_FR=os.path.join(output_path_FR,fr_txt)\n",
    "            output_file_NL=os.path.join(output_path_NL,nl_txt)\n",
    "\n",
    "            with open (output_file_NL,'w',encoding=\"utf-8\") as fp:\n",
    "                fp.write(nl_text)\n",
    "\n",
    "            with open (output_file_FR,'w',encoding=\"utf-8\") as fp:\n",
    "                fp.write(fr_text)\n",
    "\n",
    "            print (f'{document_pdf} has {x} paragraphs, NL : {t_nl}, FR: {t_fr}')\n",
    "\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the split text horizontally function\n",
    "\n",
    "split_text_horizontally()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "googenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a7e325ecc84fa625d8a3ed09038798785ca9ae88cae94e662f38988cc00c57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
