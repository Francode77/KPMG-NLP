{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED to remove files with no FR_component (from horizontal splits)\n",
    "# But in wrong language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# FASTTEXT LANGUAGE detection \n",
    "import fasttext as ft\n",
    "\n",
    "# Load the pretrained model\n",
    "ft_model = ft.load_model(\"lid.176.ftz\")\n",
    "\n",
    "def fasttext_language_predict(text, model = ft_model):\n",
    "\n",
    "  text = text.replace('\\n', \" \")\n",
    "  prediction = model.predict([text])\n",
    "\n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_languages():\n",
    "    # This function will correct the languages from the .txt files \n",
    "    # It switches the NL_ and FR_ .txt files when needed\n",
    "    #\n",
    "    # It also checks for incorrect split documents \n",
    "    # It removes their .txt files from the /processed/data folder\n",
    "    # and copies these .pdfs to /unprocessed_data/removed_from_processed\n",
    "    #\n",
    "    # To be executed after the split and process_docs_cloud\n",
    "\n",
    "    import os\n",
    "    from os import listdir\n",
    "    import time\n",
    "    import sys\n",
    "    import tempfile\n",
    "    import shutil\n",
    "\n",
    "    erroruous_split_files=[]\n",
    "    switched_docs=[]\n",
    "    not_french=0\n",
    "\n",
    "    input_language='NL'\n",
    "    opposite_language='FR'\n",
    "\n",
    "    input_path=os.path.join('../processed_data',input_language)\n",
    "    opposite_path=os.path.join('../processed_data',opposite_language)\n",
    "\n",
    "    files_in_path=listdir(input_path)\n",
    "    for file in files_in_path:\n",
    "        filename=os.path.join(input_path,file)\n",
    " \n",
    "        if 'NL_' in file:\n",
    "            document_id=file[3:]\n",
    "        else:\n",
    "            document_id=file[:]\n",
    "\n",
    "        with open(filename,encoding=\"utf-8\") as f:\n",
    "            text = f.read() \n",
    "\n",
    "        l_text=len(text) \n",
    "\n",
    "        db_check_input_language_1_half=fasttext_language_predict(text[:int(l_text/2)], model = ft_model)[0][0][0][-2:] \n",
    "        db_check_input_language_2_half=fasttext_language_predict(text[int(l_text/2):], model = ft_model)[0][0][0][-2:] \n",
    "\n",
    "        # Check if language detection is consistent throughout text\n",
    "        if db_check_input_language_1_half==db_check_input_language_2_half:           \n",
    "\n",
    "            detected_language=fasttext_language_predict(text, model = ft_model)[0][0][0][-2:]  \n",
    "\n",
    "            # Check if language detected differs from folder language\n",
    "            if detected_language.upper()!=input_language:\n",
    "                \n",
    "                try:\n",
    "                    with open (f'{opposite_path}/{opposite_language}_{document_id}',encoding=\"utf-8\") as f:\n",
    "                        opposite_text=f.read()\n",
    "                        \n",
    "                        opp_detected_language=fasttext_language_predict(opposite_text, model = ft_model)[0][0][0][-2:]  \n",
    "\n",
    "                except FileNotFoundError:\n",
    "\n",
    "                    try: \n",
    "                        with open (f'{opposite_path}/{document_id}',encoding=\"utf-8\") as f:\n",
    "                            opposite_text=f.read()                        \n",
    "                            opp_detected_language=fasttext_language_predict(opposite_text, model = ft_model)[0][0][0][-2:]  \n",
    "\n",
    "                    except FileNotFoundError:\n",
    "                        opp_detected_language='NOTFOUND'\n",
    "\n",
    "                if opp_detected_language!='NOTFOUND':\n",
    "\n",
    "                    # Check if other file actually differs in language\n",
    "                    if detected_language!=opp_detected_language:\n",
    "\n",
    "                        # Write the text to the opposite language folder\n",
    "\n",
    "                        with open (f'{opposite_path}/{opposite_language}_{document_id}','w',encoding=\"utf-8\") as fp:\n",
    "                            fp.write(text)\n",
    "\n",
    "                        # Write the opposite text to this language folder\n",
    "\n",
    "                        with open (f'{input_path}/{input_language}_{document_id}','w',encoding=\"utf-8\") as fp:\n",
    "                            fp.write(opposite_text)\n",
    "\n",
    "                        print (f\"Switched document {document_id}\",end='\\n')\n",
    "                        switched_docs.append(document_id)\n",
    "                    else:\n",
    "                        # THESE FILES WILL BE REMOVED and added back to UNPROCESSED\n",
    "\n",
    "                        erroruous_split_files.append(document_id)\n",
    "                        filename=f'{input_path}/{input_language}_{document_id}'\n",
    "                        if os.path.exists(filename):\n",
    "                            os.remove(filename)\n",
    "                        filename=f'{opposite_path}/{opposite_language}_{document_id}'\n",
    "                        if os.path.exists(filename):\n",
    "                            os.remove(filename)\n",
    "                        \n",
    "                        # Move these files back to unprocessed_data folder\n",
    "                        path=os.path.join('..','data')\n",
    "                        import glob\n",
    "                        import shutil\n",
    "                        document_id=document_id[:-4]\n",
    "\n",
    "                        for f in glob.glob(f'{path}/**', recursive=True):\n",
    "                            \n",
    "                            if f'{document_id}.pdf' in f:\n",
    "                                print(f)\n",
    "\n",
    "                                src_path=f\n",
    "                                dest_path=os.path.join('..','unprocessed_data')    \n",
    "                                dest_path=os.path.join(dest_path,'removed_from_processed')        \n",
    "\n",
    "                                if not os.path.exists(dest_path):\n",
    "                                    os.mkdir(dest_path)\n",
    "                                    \n",
    "                                dest_file=os.path.join(dest_path,document_id)\n",
    "                                dest_file=f'{dest_file}.pdf'\n",
    "                                \n",
    "                                print (f\"Notice: Removed document {document_id}\",end='\\n')\n",
    "                                shutil.copy(src_path, dest_file)\n",
    "                else:\n",
    "                    # NOT FOUND REMOVE THIS FILE\n",
    " \n",
    "                    os.remove(f'{filename}')    \n",
    "                    print (f'{input_path}/{document_id} Removed - not found in other language')\n",
    "                    not_french+=1\n",
    "\n",
    "        \"\"\"\n",
    "        else:\n",
    "            # THESE FILES WILL BE REMOVED and added back to UNPROCESSED\n",
    "\n",
    "            erroruous_split_files.append(document_id)\n",
    "            filename=f'{input_path}/{input_language}_{document_id}'\n",
    "            if os.path.exists(filename):\n",
    "                os.remove(filename)\n",
    "            filename=f'{opposite_path}/{opposite_language}_{document_id}'\n",
    "            if os.path.exists(filename):\n",
    "                os.remove(filename)\n",
    "            \n",
    "            # Move these files back to unprocessed_data folder\n",
    "            path=os.path.join('..','data')\n",
    "            import glob\n",
    "            import shutil\n",
    "            document_id=document_id[:-4]\n",
    "\n",
    "            for f in glob.glob(f'{path}/**', recursive=True):\n",
    "                \n",
    "                if f'{document_id}.pdf' in f:\n",
    "                    print(f)\n",
    "\n",
    "                    src_path=f\n",
    "                    dest_path=os.path.join('..','unprocessed_data')    \n",
    "                    dest_path=os.path.join(dest_path,'removed_from_processed')        \n",
    "\n",
    "                    if not os.path.exists(dest_path):\n",
    "                        os.mkdir(dest_path)\n",
    "                        \n",
    "                    dest_file=os.path.join(dest_path,document_id)\n",
    "                    dest_file=f'{dest_file}.pdf'\n",
    "                    \n",
    "                    print (f\"Notice: Removed document {document_id}\",end='\\n')\n",
    "                    shutil.copy(src_path, dest_file)\n",
    "                    \"\"\"\n",
    "    \n",
    "    print (f'\\nSwitched documents : {len(switched_docs)}')\n",
    "    print (f'\\nFrench docs with no counterpart : {not_french}')\n",
    "    print (f'Error documents : {len(erroruous_split_files)} files moved back to unprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Switched documents : 0\n",
      "\n",
      "French docs with no counterpart : 0\n",
      "Error documents : 0 files moved back to unprocessed\n"
     ]
    }
   ],
   "source": [
    "fix_languages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2de8b4de26c067fff13818d8da5e3f22783e9b76a9d48312d36f9bdf5037080b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
